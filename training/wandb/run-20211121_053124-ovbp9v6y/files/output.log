Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv1d (Conv1D)             (None, 7, 64)             1792
 max_pooling1d (MaxPooling1D  (None, 5, 64)            0
 )
 batch_normalization (BatchN  (None, 5, 64)            256
 ormalization)
 conv1d_1 (Conv1D)           (None, 5, 128)            49280
 max_pooling1d_1 (MaxPooling  (None, 3, 128)           0
 1D)
 batch_normalization_1 (Batc  (None, 3, 128)           512
 hNormalization)
 dropout (Dropout)           (None, 3, 128)            0
 flatten (Flatten)           (None, 384)               0
 dense (Dense)               (None, 256)               98560
 dense_1 (Dense)             (None, 128)               32896
 dense_2 (Dense)             (None, 64)                8256
 dense_3 (Dense)             (None, 32)                2080
 dropout_1 (Dropout)         (None, 32)                0
 dense_4 (Dense)             (None, 2)                 66
=================================================================
Total params: 193,698
Trainable params: 193,314
Non-trainable params: 384
_________________________________________________________________
compiling model
Epoch 1/1000
38/38 [==============================] - 1s 2ms/step - loss: 0.1601 - mse: 0.1601 - mae: 0.2743
Epoch 2/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1586
Epoch 3/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0440 - mse: 0.0440 - mae: 0.1426
Epoch 4/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0203 - mae: 0.1092
Epoch 5/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0282 - mse: 0.0282 - mae: 0.1259
Epoch 6/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0280 - mae: 0.1297
Epoch 7/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0215 - mse: 0.0215 - mae: 0.1078
Epoch 8/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.0958
Epoch 9/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0199 - mse: 0.0199 - mae: 0.1074
Epoch 10/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0829
Epoch 11/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0951
Epoch 12/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0780
Epoch 13/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0922
Epoch 14/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0797
Epoch 15/1000
 1/38 [..............................] - ETA: 0s - loss: 0.0072 - mse: 0.0072 - mae: 0.0822
2021-11-21 05:31:26.127054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-21 05:31:26.127477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-21 05:31:26.127556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory
2021-11-21 05:31:26.127618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory
2021-11-21 05:31:26.127679: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2021-11-21 05:31:26.127740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2021-11-21 05:31:26.127800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory
2021-11-21 05:31:26.127860: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory
2021-11-21 05:31:26.127918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2021-11-21 05:31:26.127939: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-11-21 05:31:26.128239: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
38/38 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0887
Epoch 16/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0839
Epoch 17/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0810
Epoch 18/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0801
Epoch 19/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0819
Epoch 20/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0957
Epoch 21/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0734
Epoch 22/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0890
Epoch 23/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0829
Epoch 24/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0772
Epoch 25/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0794
Epoch 26/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0740
Epoch 27/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0710
Epoch 28/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0799
Epoch 29/1000
38/38 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0750
Epoch 30/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0743
Epoch 31/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0730
Epoch 32/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0671
Epoch 33/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0777
Epoch 34/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0843
Epoch 35/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0677
Epoch 36/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0714
Epoch 37/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0756
Epoch 38/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0700
Epoch 39/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0679
Epoch 40/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0579
Epoch 41/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0643
Epoch 42/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0701
Epoch 43/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0609
Epoch 44/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0588
Epoch 45/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0593
Epoch 46/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0683
Epoch 47/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0553
Epoch 48/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0700
Epoch 49/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0605
Epoch 50/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0669
Epoch 51/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0598
Epoch 52/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0532
Epoch 53/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0708
Epoch 54/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0709
Epoch 55/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0592
Epoch 56/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0633
Epoch 57/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0638
Epoch 58/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0661
Epoch 59/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0601
Epoch 60/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0648
Epoch 61/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0635
Epoch 62/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0648
Epoch 63/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0610
Epoch 64/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0613
Epoch 65/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0553
Epoch 66/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0650
Epoch 67/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0653
Epoch 68/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0610
Epoch 69/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0551
Epoch 70/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0593
Epoch 71/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0622
Epoch 72/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0565
Epoch 73/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0562
Epoch 74/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0592
Epoch 75/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0551
Epoch 76/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0623
Epoch 77/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0596
Epoch 78/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0663
Epoch 79/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0613
Epoch 80/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0642
Epoch 81/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0593
Epoch 82/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0507
Epoch 83/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0625
Epoch 84/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0467
Epoch 85/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0541
Epoch 86/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0474
Epoch 87/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0652
Epoch 88/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0539
Epoch 89/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0549
Epoch 90/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0521
Epoch 91/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0586
Epoch 92/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0708
Epoch 93/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0430
Epoch 94/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0485
Epoch 95/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0556
Epoch 96/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0508
Epoch 97/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0485
Epoch 98/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0571
Epoch 99/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0441
Epoch 100/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0468
Epoch 101/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0529
Epoch 102/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0568
Epoch 103/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0582
Epoch 104/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0541
Epoch 105/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0527
Epoch 106/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0512
Epoch 107/1000
38/38 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0502
Epoch 108/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0451
Epoch 109/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0495
Epoch 110/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0487
Epoch 111/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0480
Epoch 112/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0459
Epoch 113/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0427
Epoch 114/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0487
Epoch 115/1000
38/38 [==============================] - 0s 3ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0533
Epoch 116/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0546
Epoch 117/1000
38/38 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0551
Epoch 118/1000
 1/38 [..............................] - ETA: 0s - loss: 0.0031 - mse: 0.0031 - mae: 0.0513
38/38 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0541
38/38 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0541
Traceback (most recent call last):
  File "/sata/code/limestone/train.py", line 56, in <module>
    model.fit(data, labls, BATCHES, EPOCHS, shuffle=True, callbacks=[WandbCallback()])
  File "/home/james/.local/lib/python3.9/site-packages/wandb/integration/keras/keras.py", line 168, in new_v2
    return old_v2(*args, **kwargs)
  File "/home/james/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py", line 64, in error_handler
    return fn(*args, **kwargs)
  File "/home/james/.local/lib/python3.9/site-packages/keras/engine/training.py", line 1221, in fit
    callbacks.on_train_batch_end(end_step, logs)
  File "/home/james/.local/lib/python3.9/site-packages/keras/callbacks.py", line 436, in on_train_batch_end
    self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)
  File "/home/james/.local/lib/python3.9/site-packages/keras/callbacks.py", line 295, in _call_batch_hook
    self._call_batch_end_hook(mode, batch, logs)
  File "/home/james/.local/lib/python3.9/site-packages/keras/callbacks.py", line 316, in _call_batch_end_hook
    self._call_batch_hook_helper(hook_name, batch, logs)
  File "/home/james/.local/lib/python3.9/site-packages/keras/callbacks.py", line 354, in _call_batch_hook_helper
    hook(batch, logs)
  File "/home/james/.local/lib/python3.9/site-packages/keras/callbacks.py", line 1032, in on_train_batch_end
    self._batch_update_progbar(batch, logs)
  File "/home/james/.local/lib/python3.9/site-packages/keras/callbacks.py", line 1090, in _batch_update_progbar
    self._maybe_init_progbar()
  File "/home/james/.local/lib/python3.9/site-packages/keras/callbacks.py", line 1067, in _maybe_init_progbar
    set(m.name for m in self.model.metrics))
  File "/home/james/.local/lib/python3.9/site-packages/keras/engine/training.py", line 686, in metrics
    if self._is_compiled:
KeyboardInterrupt